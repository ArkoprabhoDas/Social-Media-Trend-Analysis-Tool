{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pinterestData.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpinterestData.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      2\u001b[0m     dataList \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m      3\u001b[0m dataList \u001b[38;5;241m=\u001b[39m [item\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m dataList]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pinterestData.txt'"
     ]
    }
   ],
   "source": [
    "with open(\"pinterestData.txt\",\"r\") as file:\n",
    "    dataList = file.readlines()\n",
    "dataList = [item.strip() for item in dataList]\n",
    "post_list.extend(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"facebookPost.txt\",\"r\", encoding=\"utf-8\") as file:\n",
    "    dataList = file.readlines()\n",
    "dataList = [item.strip() for item in dataList]\n",
    "post_list.extend(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"redditPost.txt\",\"r\", encoding=\"utf-8\") as file:\n",
    "    dataList = file.readlines()\n",
    "dataList = [item.strip() for item in dataList]\n",
    "post_list.extend(dataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"keyword.txt\",\"r\") as file:\n",
    "    hashtag_to_search = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['christmas boys',\n",
       " 'merry christmas',\n",
       " 'aww christmasclub',\n",
       " 'pics happyhungryhijabi',\n",
       " 'practicalday9048 christmaslights']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_keyword = []\n",
    "def extract_topics(posts, num_topics = 5):\n",
    "    vectorizer = TfidfVectorizer(max_df=0.85, max_features=1000, stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(posts)\n",
    "    \n",
    "    nmf = NMF(n_components=num_topics, random_state=42)\n",
    "    nmf.fit(tfidf_matrix)\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    for i,topic in enumerate(nmf.components_):\n",
    "        top_words_idx = topic.argsort()[:-10-1:-1]\n",
    "        top_words = [feature_names[idx] for idx in top_words_idx]\n",
    "        list_keyword.append(\" \".join(top_words[0:2]))\n",
    "extract_topics(post_list)\n",
    "list_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Christmas on more people : Christmas tree. My christmas :',\n",
       " 'Christmas boys, Christmas…',\n",
       " 'Oh, Christmas Cat oh Christmas cat…',\n",
       " 'Grandpa won Christmas!',\n",
       " 'Christmas lights and christmas market, first ever street photography session.',\n",
       " '“Christmas with DOOM” a virtual christmas card',\n",
       " 'Christmas',\n",
       " 'Celebrate Christmas With Creative Christmas Trees!!🎄🎄❤️💚',\n",
       " 'Christmas',\n",
       " 'Christmas wishlist :',\n",
       " '\"No, he\\'s the Christmas Rapist! He rapes on Christmas! Is nothing sacred?!\"',\n",
       " 'Merry Christmas!!!⛄🎅🦌',\n",
       " \"It's a Christmas miracle\",\n",
       " 'Magical Christmas Fireplace • 10-Hour Christmas Ambience',\n",
       " 'Spending Christmas away from family this year…..merry Christmas to me!',\n",
       " 'Christmas humour',\n",
       " 'New Christmas Tree + Christmas decorations + Chinese NY decorations Leaked by Clash Kurdish',\n",
       " 'Christmas Blessings',\n",
       " 'Christmas 2023',\n",
       " 'Christmas time',\n",
       " 'Christmas Gifting',\n",
       " 'Christmas came early',\n",
       " 'r/christmas',\n",
       " 'r/ChristmasDecorating',\n",
       " 'r/ChristmasLights',\n",
       " 'r/pics',\n",
       " 'r/aww',\n",
       " 'u/ChristmasOf1984',\n",
       " 'u/ChristmasClub',\n",
       " 'u/PracticalDay9048',\n",
       " 'u/happyhungryhijabi',\n",
       " 'u/OzBargainBot']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_bert_embeddings(posts):\n",
    "    model_name = 'bert-base-uncased'\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "    if isinstance(posts, str):\n",
    "        posts = [posts]\n",
    "    \n",
    "    encoded_posts = tokenizer(posts, return_tensors='pt', padding = True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_posts)\n",
    "        embeddings = outputs['last_hidden_state'][:,0, :].numpy()\n",
    "    return embeddings\n",
    "\n",
    "def compute_cosine_similarity(post_embeddings, topic_embedding):\n",
    "    post_embeddings = post_embeddings.reshape(post_embeddings.shape[0],-1)\n",
    "    topic_embedding = topic_embedding.reshape(1, -1)\n",
    "    similarities = cosine_similarity(post_embeddings, topic_embedding)\n",
    "    return similarities.flatten()\n",
    "\n",
    "def find_relevance_to_topic(posts, topic, threshold = 0.5):\n",
    "    post_embeddings = get_bert_embeddings(posts)\n",
    "    topic_embedding = get_bert_embeddings(topic)\n",
    "    similarities = compute_cosine_similarity(post_embeddings,topic_embedding)\n",
    "    relevant_posts = [post for post, sim in zip(posts, similarities) if sim > threshold]\n",
    "    return relevant_posts\n",
    "\n",
    "relevant_posts = find_relevance_to_topic(post_list,hashtag_to_search)\n",
    "relevant_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(len(relevant_posts) > 10):\n",
    "    relevant_posts = relevant_posts[:10]\n",
    "if(len(list_keyword) > 5) : \n",
    "    list_keyword = list_keyword[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"post.txt\",\"w\", encoding=\"utf-8\") as file:\n",
    "    for post in relevant_posts:\n",
    "        file.write(str(post) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"postKeyword.txt\",\"w\", encoding=\"utf-8\") as file:\n",
    "    for post in list_keyword:\n",
    "        file.write(str(post) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
